AI Usage Journal
Julian Tubel
jtubel@umd.edu
Section 0302

Week 1
I didn't really use AI that much this week, one instance of me using chatgpt was to try and route audio from my DAW instead of using a virtual mixing software.
https://chatgpt.com/share/68c72545-7658-8012-a372-a4d10215e321

Week 2 
I used AI to help make a comparison chart between two philosophers for class review
https://chatgpt.com/share/68cf85d1-351c-800a-b184-e1305addb8ef

Week 3
I used AI to help me review and clarify concepts for philosophy once again
https://chatgpt.com/share/68d9bd1b-ad9c-800a-89b8-eb44d1f64888

Week4
I used AI to help me review for my philosophy midterm
https://chatgpt.com/share/68e2de4c-cb2c-8012-ab57-dbc7df7e8252

Week5
I used AI to help me brainstorm functions for our project
https://chatgpt.com/share/68e98167-6c10-8003-9c16-54e0cda53562

***Which functions received AI assistance
•	validate_case_entry()
•	format_date()
•	clean_case_data()

I discussed overall structure and strategies for validation, data cleaning, and date normalization with ChatGPT. 
The functions generate_epidemic_summary() and other logic were implemented independently without AI guidance.

***What prompts you used and why
I used AI mainly to brainstorm approaches and clarify best practices for structuring small utility functions.
•	Prompt 1:
“I’m building a function that validates case data for a public health dataset. It’s a list of dictionaries with date, location, and case count. How can I approach this in Python without using libraries like pandas?”
I asked this because I wanted a simple, library-free way to validate nested dictionaries. AI helped outline a clean structure for looping through records and checking key validity.
•	Prompt 2:
“Some of the case dates in my data look like ‘03/01/25’ or ‘2025-03-01.’ I just need them to be consistent. What’s a simple way to standardize them without external libraries?”
I used this to learn about Python’s built-in methods for parsing and reformatting dates. AI introduced the idea of using .zfill() for zero-padding and replacing slashes with dashes, which I later customized.
These conversations were mainly for conceptual and formatting guidance — all final code was rewritten and adapted for my project’s domain.
***How you validated and modified AI suggestions
After receiving the AI examples, I made several changes before integrating anything:
•	Simplified structure: I rewrote the validate_case_entry() function to focus only on existence and emptiness checks, rather than relying on external validation modules or exceptions.
I tested each function with sample datasets containing bad entries (missing keys, invalid dates, non-integer cases) and verified that the cleaning process worked correctly end to end.
***What you learned from the AI collaboration process
•	I realized that AI can provide a helpful scaffold, but manual review is essential to catch subtle domain errors and ensure readability.
•	I gained experience in verifying AI-generated logic by writing test examples and comparing outputs to expected results.
•	It reinforced that I should treat AI output as a draft, not a finished product.
***Decisions you made to improve AI-generated code
•	Added stricter validation: Introduced input type checks and explicit "INVALID" outputs instead of silent failures.
•	Improved readability: Wrote detailed docstrings with examples and parameter explanations.
•	Extended scope: Expanded the cleaning process to handle capitalization (.title() for locations) and numeric conversion for case counts.

Week6
I used AI to help me review for my Myth midterm
https://chatgpt.com/share/68fd359b-88e8-8012-821b-aaa9b523aeee

Week7
I used AI to help me plan and review the object-oriented design for my part of the project.
https://chatgpt.com/share/6907d6b9-d0c0-8012-94e4-1674aaa5dbdb
Which classes received AI assistance

• CaseRecord
• CaseDataset

I discussed how to convert procedural code from Project 1 into a class-based design and how to add validation and encapsulation properly.
The rest of the logic—cleaning, filtering, and summarizing was written and tested independently after reviewing AI examples.

Prompts I used

• Prompt 1:
“I’m trying to convert my Project 1 public-health data functions into a class. How should I start defining a simple CaseRecord class with attributes like date, location, age, and cases, including validation inside __init__?”
I used this to understand how to structure the class so that validation happened automatically when creating new records.
AI helped outline a clean constructor format and the idea of using helper methods to organize validation.
• Prompt 2:
“If I want each case record to validate its fields automatically, should I use helper methods or property setters? I’m not sure how to keep the constructor clean but still check the inputs.”
This helped me compare different approaches for encapsulation and decide to keep internal helper methods (like _validate_age and _format_date) for clarity.
• Prompt 3:
“How can I make sure my dataset methods use clear names that match my Project 1 functions? I want it to feel consistent but organized for OOP.”
I used this to plan method naming in a way that stayed familiar from Project 1 while still fitting OOP style conventions.

Week8
I used AI to help fix my bike
https://chatgpt.com/share/690d278e-5f3c-800a-a49d-747f15b04856

Week9
I used AI to help review Avian Evolution
https://chatgpt.com/share/6912a8e7-0638-8003-864e-8369c540c96c

Week10
I used AI to help me plan and review the object-oriented design for my part of the project.
https://gemini.google.com/share/49b9bcaeea33

Which classes received AI assistance

• CaseRecord
• CaseDataset

I discussed how to restructure my existing single-class design into an inheritance hierarchy to support multiple file formats without duplicating code. 
The rest of the logic as written and tested independently after reviewing the architectural advice.

Prompts I used

•Prompt 1:
"I currently have a single CaseDataset class that only loads CSV files. For Project 3, I need to support JSON files as well. From an OOP perspective,
does it make more sense to add if/else checks inside my existing class, or should I create a parent Dataset class with two children: CSVDataset and JSONDataset?
I want to follow best practices for scalability."
•Prompt 2:
"I decided to use an abstract base class. Can you provide the standard Python boilerplate code for creating a class named AbstractDataset using the abc module? 
I need to ensure that any child class is forced to implement load_data and validate_format."
•Prompt 3: 
"I'm confused about where my CaseRecord class fits in. Should CSVDataset inherit from CaseRecord, or should the dataset contain a list of CaseRecord objects?
I need to demonstrate 'composition,' 
but I want to make sure it makes logical sense for this specific domain."
•Prompt 4:
"I want to loop through a list containing both CSVDataset and JSONDataset objects and load them all at once. If I call .load_data() on items in the list, 
how does Python know which version of the method (the CSV one or the JSON one) to run?"

Week12
I used AI to help fix my bike
https://gemini.google.com/share/e24824a6369c

Week 13
I used AI to help me understand how to implement data persistence for complex custom objects and to clarify the distinction between "Integration" and "System" testing for our final test suite.

Link to Chat: https://gemini.google.com/share/6fb4fcdcaa6f

Which classes received AI assistance:
-XMLDataset (Refactored from Kindness's DataLoader)
-AbstractAnalyzer (New Interface)
-TrendAnalyzer (Refactored from Kindness)
-ForecastingAnalyzer (Refactored from Yonael)
-PipelineManager (Persistence logic)
-test_suite_v2.py (Test structure)
-test_case_manager.py (Integration logic)

Summary of Interaction: I discussed options for saving our application state, weighing the pros and cons of JSON versus Python’s pickle module for handling our custom AbstractDataset classes. 
I also asked for clarification on the academic difference between "Integration" and "System" tests to ensure our test suite met the specific rubric requirements. The actual test cases and the pickle implementation were written and debugged by me.

Prompts I used
• Prompt 1:
"I need to satisfy the 'Data Persistence' requirement for my final project. My PipelineManager class contains a list of custom Dataset objects. Is it better to manually write a to_json() method for every single class to save them, 
or is there a standard Python module that can serialize the whole object graph at once? I need the most reliable method for a student project."
• Prompt 2:
"My assignment requires both 'Integration Tests' and 'System Tests.' I am using the unittest framework. What is the conceptual difference between these two in the context of a data processing pipeline? 
Can you give me a conceptual example of what an integration test would check versus what a system test would check?"
• Prompt 3:
"I am merging code from three different teammates. One has a TrendAnalyzer and another has a ForecastingAnalyzer. I want my PipelineManager to run them all without using hardcoded if/else statements checking for specific class names. 
How can I use polymorphism here to just call .analyze() on a generic list of tools?"

Pt. 2
Link to Chat: https://gemini.google.com/share/90f7064f9814
I pasted snippets of my teammates' Project 2 code (a "universal" data loader and a standalone forecaster) and asked for architectural advice on how to split them up. 
I specifically discussed how to extract the XML parsing logic into its own class without breaking the existing functionality, and how to create a generic analyze() method that could handle both statistical summaries (Kindness) and future predictions (Yonael) polymorphically.

Prompts I used
• Prompt 1 (Refactoring Kindness's Loader):
"My teammate submitted a single DataLoader class that handles CSV, JSON, and XML files using a long chain of if/elif statements. I need to refactor this to fit my new AbstractDataset hierarchy. 
How can I extract just the XML parsing logic into a new class called XMLDataset? I want it to inherit from my base class but keep his specific xml.etree logic."
• Prompt 2 (Designing the Analysis Interface):
"We have two different analysis needs: one for calculating basic trends (averages) and one for predicting future cases. Currently, they are completely different classes with different method names. 
I want to create an AbstractAnalyzer parent class so our pipeline can run them both in a loop. What should the abstract method signature look like? Should it return a dictionary so both classes can output different types of results?"
• Prompt 3 (Refactoring Yonael's Forecaster):
"I am refactoring a class called EpidemicForecaster. Currently, it stores data inside self.daily_cases when it is initialized. However, for our new pipeline, we want to pass data into the analyzer dynamically. 
How should I rewrite the class to be 'stateless'—so that I pass the records directly into the analyze() method instead of storing them in __init__?"

